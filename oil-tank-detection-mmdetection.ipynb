{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Install MMDetection**","metadata":{}},{"cell_type":"code","source":"!nvcc -V\n!gcc --version ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-18T15:35:14.036815Z","iopub.execute_input":"2023-09-18T15:35:14.037176Z","iopub.status.idle":"2023-09-18T15:35:16.012909Z","shell.execute_reply.started":"2023-09-18T15:35:14.037140Z","shell.execute_reply":"2023-09-18T15:35:16.011864Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2020 NVIDIA Corporation\nBuilt on Wed_Jul_22_19:09:09_PDT_2020\nCuda compilation tools, release 11.0, V11.0.221\nBuild cuda_11.0_bu.TC445_37.28845127_0\ngcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U torch==1.7.1+cu110 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n!pip install mmcv-full\n!rm -rf mmdetection\n!git clone https://github.com/open-mmlab/mmdetection\n%cd mmdetection\n!pip install -e .\n!pip install Pillow==7.0.0","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:35:22.165666Z","iopub.execute_input":"2023-09-18T15:35:22.166049Z","iopub.status.idle":"2023-09-18T15:53:36.183319Z","shell.execute_reply.started":"2023-09-18T15:35:22.166010Z","shell.execute_reply":"2023-09-18T15:53:36.181764Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Looking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch==1.7.1+cu110\n  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n\u001b[K     |████████████████████████████    | 1009.0 MB 64.2 MB/s eta 0:00:03   |██▎                             | 80.5 MB 57.8 MB/s eta 0:00:19     |██▌                             | 89.5 MB 30.3 MB/s eta 0:00:36     |██▌                             | 92.3 MB 30.3 MB/s eta 0:00:36     |██▊                             | 97.0 MB 30.3 MB/s eta 0:00:36     |████▍                           | 159.5 MB 60.8 MB/s eta 0:00:17MB/s eta 0:00:17     |█████▌                          | 200.6 MB 67.6 MB/s eta 0:00:15     |███████▎                        | 265.0 MB 36.9 MB/s eta 0:00:25     |██████████████▌                 | 522.7 MB 49.8 MB/s eta 0:00:13MB/s eta 0:00:08     |███████████████████             | 690.7 MB 59.5 MB/s eta 0:00:08     |███████████████████▏            | 691.9 MB 59.5 MB/s eta 0:00:08     |███████████████████▊            | 712.9 MB 48.3 MB/s eta 0:00:10     |████████████████████            | 722.1 MB 12.8 MB/s eta 0:00:34�███████████        | 871.2 MB 60.1 MB/s eta 0:00:05984.8 MB 64.7 MB/s eta 0:00:03  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.8.1\n    Uninstalling torchvision-0.8.1:\n      Successfully uninstalled torchvision-0.8.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.7.1+cu110 torchvision-0.8.2+cu101\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting mmcv-full\n  Downloading mmcv-full-1.7.1.tar.gz (605 kB)\n\u001b[K     |████████████████████████████████| 605 kB 24.8 MB/s eta 0:00:01\n\u001b[?25hCollecting addict\n  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (1.19.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (20.9)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (8.2.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (5.4.1)\nCollecting yapf\n  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n\u001b[K     |███████████████████████████████▍| 245 kB 77.4 MB/s eta 0:00:01     |████████████████████████████████| 250 kB 77.4 MB/s \n\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->mmcv-full) (2.4.7)\nCollecting tomli>=2.0.1\n  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting platformdirs>=3.5.1\n  Downloading platformdirs-3.10.0-py3-none-any.whl (17 kB)\nCollecting importlib-metadata>=6.6.0\n  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full) (3.4.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full) (3.7.4.3)\nCollecting typing-extensions>=3.6.4\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nBuilding wheels for collected packages: mmcv-full\n  Building wheel for mmcv-full (setup.py) ... \u001b[?25l|^C\n\u001b[?25canceled\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\nCloning into 'mmdetection'...\nremote: Enumerating objects: 37285, done.\u001b[K\nremote: Counting objects: 100% (775/775), done.\u001b[K\nremote: Compressing objects: 100% (408/408), done.\u001b[K\nremote: Total 37285 (delta 393), reused 606 (delta 365), pack-reused 36510\u001b[K\nReceiving objects: 100% (37285/37285), 59.25 MiB | 18.67 MiB/s, done.\n^Csolving deltas:  11% (2883/26074)   \n[Errno 2] No such file or directory: 'mmdetection'\n/kaggle/working\n\u001b[31mERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: /kaggle/working\u001b[0m\nCollecting Pillow==7.0.0\n  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n\u001b[K     |████████████████████████████████| 2.1 MB 20.2 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: Pillow\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 8.2.0\n    Uninstalling Pillow-8.2.0:\n      Successfully uninstalled Pillow-8.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbokeh 2.3.2 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\u001b[0m\nSuccessfully installed Pillow-7.0.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\nimport mmdet as mmdet\nprint(mmdet.__version__)\n\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())\n\nimport os\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nimport glob\nimport cv2\nimport shutil\nimport random\nimport os.path as osp\nimport json\nimport numpy as np\nimport pandas as pd\nimport mmcv\nfrom mmdet.apis import set_random_seed\nimport re\nimport xml.etree.ElementTree as ET\nfrom typing import Dict, List\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:59:35.784646Z","iopub.execute_input":"2023-09-18T15:59:35.785049Z","iopub.status.idle":"2023-09-18T15:59:35.808795Z","shell.execute_reply.started":"2023-09-18T15:59:35.785013Z","shell.execute_reply":"2023-09-18T15:59:35.807462Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"1.7.0 True\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-ea331d7cad08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmmdet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmdet'"],"ename":"ModuleNotFoundError","evalue":"No module named 'mmdet'","output_type":"error"}]},{"cell_type":"code","source":"global_seed = 0\n\ndef set_seed(seed=global_seed):\n    \"\"\"Sets the random seeds.\"\"\"\n    set_random_seed(seed, deterministic=False)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:59:43.078194Z","iopub.execute_input":"2023-09-18T15:59:43.078602Z","iopub.status.idle":"2023-09-18T15:59:43.103600Z","shell.execute_reply.started":"2023-09-18T15:59:43.078567Z","shell.execute_reply":"2023-09-18T15:59:43.102131Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-f064955e79f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONHASHSEED'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-f064955e79f5>\u001b[0m in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Sets the random seeds.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'set_random_seed' is not defined"],"ename":"NameError","evalue":"name 'set_random_seed' is not defined","output_type":"error"}]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:59:55.447458Z","iopub.execute_input":"2023-09-18T15:59:55.447830Z","iopub.status.idle":"2023-09-18T15:59:55.453671Z","shell.execute_reply.started":"2023-09-18T15:59:55.447797Z","shell.execute_reply":"2023-09-18T15:59:55.452728Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Convert to COCO Annotations**","metadata":{}},{"cell_type":"code","source":"with open('../input/oil-storage-tanks/Oil Tanks/labels.json', 'r') as f:\n    data = f.read()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:00:45.221934Z","iopub.execute_input":"2023-09-18T16:00:45.222303Z","iopub.status.idle":"2023-09-18T16:00:45.242524Z","shell.execute_reply.started":"2023-09-18T16:00:45.222267Z","shell.execute_reply":"2023-09-18T16:00:45.240634Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8cfd939cbf0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/input/oil-storage-tanks/Oil Tanks/labels.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input/oil-storage-tanks/Oil Tanks/labels.json'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/input/oil-storage-tanks/Oil Tanks/labels.json'","output_type":"error"}]},{"cell_type":"code","source":"data = json.loads(data)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T13:01:22.003012Z","iopub.execute_input":"2021-08-05T13:01:22.003408Z","iopub.status.idle":"2021-08-05T13:01:22.212422Z","shell.execute_reply.started":"2021-08-05T13:01:22.003368Z","shell.execute_reply":"2021-08-05T13:01:22.211266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[4]['label']","metadata":{"execution":{"iopub.status.busy":"2021-08-05T13:24:29.853751Z","iopub.execute_input":"2021-08-05T13:24:29.854091Z","iopub.status.idle":"2021-08-05T13:24:29.864689Z","shell.execute_reply.started":"2021-08-05T13:24:29.854059Z","shell.execute_reply":"2021-08-05T13:24:29.863457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annots = []\nfor annot in data:\n    if annot['label'] != 'Skip':\n        annots.append(annot['id'])","metadata":{"execution":{"iopub.status.busy":"2021-08-05T13:28:20.206401Z","iopub.execute_input":"2021-08-05T13:28:20.206772Z","iopub.status.idle":"2021-08-05T13:28:20.214222Z","shell.execute_reply.started":"2021-08-05T13:28:20.20674Z","shell.execute_reply":"2021-08-05T13:28:20.21325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile labels.txt\nTank\nTank Cluster\nFloating Head Tank","metadata":{"execution":{"iopub.status.busy":"2021-08-05T13:34:34.165591Z","iopub.execute_input":"2021-08-05T13:34:34.165939Z","iopub.status.idle":"2021-08-05T13:34:34.172026Z","shell.execute_reply.started":"2021-08-05T13:34:34.165907Z","shell.execute_reply":"2021-08-05T13:34:34.170921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"non_annots = []\nfor i in range(len(data)):\n    idx = data[i]['id']\n    if idx not in annots:\n        non_annots.append(idx)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T14:25:37.222596Z","iopub.execute_input":"2021-08-05T14:25:37.222934Z","iopub.status.idle":"2021-08-05T14:25:37.41954Z","shell.execute_reply.started":"2021-08-05T14:25:37.222905Z","shell.execute_reply":"2021-08-05T14:25:37.418626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train, Val Split","metadata":{}},{"cell_type":"code","source":"non_annots_sample = random.sample(non_annots, 350)\ntrain_non_annots = random.sample(non_annots_sample, 300)\nval_non_annots = []\nfor idx in non_annots_sample:\n    if idx not in train_non_annots:\n        val_non_annots.append(idx)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T14:34:30.194386Z","iopub.execute_input":"2021-08-05T14:34:30.194729Z","iopub.status.idle":"2021-08-05T14:34:30.201865Z","shell.execute_reply.started":"2021-08-05T14:34:30.194695Z","shell.execute_reply":"2021-08-05T14:34:30.200913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annots_sample = random.sample(annots, 350)\ntrain_annots = random.sample(annots_sample, 300)\nval_annots = []\nfor idx in annots_sample:\n    if idx not in train_annots:\n        val_annots.append(idx)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T14:36:49.824655Z","iopub.execute_input":"2021-08-05T14:36:49.824987Z","iopub.status.idle":"2021-08-05T14:36:49.833359Z","shell.execute_reply.started":"2021-08-05T14:36:49.824957Z","shell.execute_reply":"2021-08-05T14:36:49.83222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_coco(annot_idx_list, non_annot_idx_list, output_json_path, data=data, labels=['Tank', 'Tank Cluster', 'Floating Head Tank'], starting_bbox_id=1):\n    output_json_dict = {\n        'images': [],\n        'annotations': [],\n        'categories' : []\n    }\n    for annot_idx in annot_idx_list:\n        for label in data[annot_idx]['label']:\n            if label == labels[0]:\n                label_id = 0\n            elif label == labels[1]:\n                label_id = 1\n            elif label == labels[2]:\n                label_id = 2\n            else:\n                raise ValueError('Category is not recognized')\n            for rect in data[annot_idx]['label'][label]:\n                xmin = rect['geometry'][0]['x']\n                ymin = rect['geometry'][0]['y']\n                xmax = rect['geometry'][2]['x']\n                ymax = rect['geometry'][1]['y']\n                bbox_width = xmax - xmin\n                bbox_height = ymax - ymin\n                bbox_area = bbox_width * bbox_height\n                img_id = data[annot_idx]['id']\n                bbox_id = starting_bbox_id\n                starting_bbox_id = starting_bbox_id + 1\n                annot = {\n                    'category_id': label_id,\n                    'segmentation': [],\n                    'area': bbox_area,\n                    'bbox': [xmin, ymin, bbox_width, bbox_height],\n                    'id': bbox_id,\n                    'image_id': img_id,\n                    'iscrowd': 0\n                }\n                output_json_dict['annotations'].append(annot)\n        file_name = data[annot_idx]['file_name']\n        img_info = {\n            'id': img_id,\n            'width': 512,\n            'height': 512,\n            'file_name': file_name\n        }\n        output_json_dict['images'].append(img_info)\n    \n    for non_annot_idx in non_annot_idx_list:\n        file_name = data[non_annot_idx]['file_name']\n        img_id = data[non_annot_idx]['id']\n        img_info = {\n            'id': img_id,\n            'width': 512,\n            'height': 512,\n            'file_name': file_name\n        }\n        output_json_dict['images'].append(img_info)\n    for i, label in enumerate(labels):\n        category_info = {\n            'id': i,\n            'name': label,\n            'supercategory': 'none'\n        }\n        output_json_dict['categories'].append(category_info)\n        \n    with open(output_json_path, 'x') as f:\n        output_json = json.dumps(output_json_dict)\n        f.write(output_json)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:33:06.680494Z","iopub.execute_input":"2021-08-05T15:33:06.680845Z","iopub.status.idle":"2021-08-05T15:33:06.696383Z","shell.execute_reply.started":"2021-08-05T15:33:06.680813Z","shell.execute_reply":"2021-08-05T15:33:06.695127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_coco(annot_idx_list=train_annots, non_annot_idx_list=train_non_annots, output_json_path='/kaggle/working/output.json')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:33:08.407365Z","iopub.execute_input":"2021-08-05T15:33:08.407727Z","iopub.status.idle":"2021-08-05T15:33:08.431246Z","shell.execute_reply.started":"2021-08-05T15:33:08.407695Z","shell.execute_reply":"2021-08-05T15:33:08.430377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_coco(annot_idx_list=val_annots, non_annot_idx_list=val_non_annots, output_json_path='/kaggle/working/val-output.json')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:33:08.99961Z","iopub.execute_input":"2021-08-05T15:33:09.00009Z","iopub.status.idle":"2021-08-05T15:33:09.009534Z","shell.execute_reply.started":"2021-08-05T15:33:09.000047Z","shell.execute_reply":"2021-08-05T15:33:09.008277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Custom Config File With Deformable CNN V2**","metadata":{}},{"cell_type":"code","source":"from mmcv import Config\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/dcn/cascade_rcnn_r101_fpn_dconv_c3-c5_1x_coco.py')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:33:13.166168Z","iopub.execute_input":"2021-08-05T15:33:13.166548Z","iopub.status.idle":"2021-08-05T15:33:13.19714Z","shell.execute_reply.started":"2021-08-05T15:33:13.166517Z","shell.execute_reply":"2021-08-05T15:33:13.196335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.apis import set_random_seed\n\ncfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = 'val-output.json'\ncfg.data.test.img_prefix = '../input/oil-storage-tanks/Oil Tanks/image_patches'\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = 'output.json'\ncfg.data.train.img_prefix = '../input/oil-storage-tanks/Oil Tanks/image_patches'\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = 'val-output.json'\ncfg.data.val.img_prefix = '../input/oil-storage-tanks/Oil Tanks/image_patches'\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n    dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n         contrast_limit=0.2, p=0.5),\n    dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n#     dict(type='MixUp', p=0.2, lambd=0.5),\n#     dict(type=\"Blur\", p=1.0, blur_limit=7),\n#     dict(type='CLAHE', p=0.5),\n#     dict(type='Equalize', mode='cv', p=0.4),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='coco',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(512, 512),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.load_from = '../input/dcn-checkpoint/cascade_rcnn_r101_fpn_dconv_c3-c5_1x_coco_20200203-3b2f0594.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\n\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=500, \n    warmup_ratio=0.001,\n    min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 4\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'bbox'\ncfg.evaluation.interval = 4\n\ncfg.checkpoint_config.interval = 12\ncfg.runner.max_epochs = 12\ncfg.log_config.interval = 50\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:33:13.764555Z","iopub.execute_input":"2021-08-05T15:33:13.764883Z","iopub.status.idle":"2021-08-05T15:33:14.579471Z","shell.execute_reply.started":"2021-08-05T15:33:13.764854Z","shell.execute_reply":"2021-08-05T15:33:14.578519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(\n cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:33:15.572162Z","iopub.execute_input":"2021-08-05T15:33:15.572563Z","iopub.status.idle":"2021-08-05T15:57:30.443688Z","shell.execute_reply.started":"2021-08-05T15:33:15.572528Z","shell.execute_reply":"2021-08-05T15:57:30.442676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = init_detector(cfg, '/kaggle/working/model_output/epoch_12.pth')\nfor i in range(30):\n    img = data[annots[500+i]]['file_name']\n    img = mmcv.imread('../input/oil-storage-tanks/Oil Tanks/image_patches/' + img)\n    result = inference_detector(model, img)\n    show_result_pyplot(model, img, result)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport random\nimport json\nimport numpy as np\nimport mmcv\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector, inference_detector, init_detector, show_result_pyplot\nfrom mmdet.apis import set_random_seed\nfrom mmcv import Config\n\n# Set a random seed for reproducibility\nset_random_seed(0, deterministic=False)\n\n# Load JSON data containing object annotations\nwith open('annotations.json', 'r') as f:\n    data = json.load(f)\n\n# Separate annotations into annotated and non-annotated categories\nannots = [annot['id'] for annot in data if annot['label'] != 'Skip']\nnon_annots = [annot['id'] for annot in data if annot['label'] == 'Skip']\n\n# Randomly split annotations into training and validation sets\ntrain_annots = random.sample(annots, 300)\nval_annots = [idx for idx in annots if idx not in train_annots]\n\n# Randomly sample non-annotations for training and validation sets\nnon_annots_sample = random.sample(non_annots, 350)\ntrain_non_annots = random.sample(non_annots_sample, 300)\nval_non_annots = [idx for idx in non_annots_sample if idx not in train_non_annots]\n\n# Create COCO-style annotation files for training and validation datasets\ndef convert_to_coco(annot_idx_list, non_annot_idx_list, output_json_path):\n    \n    # Construct COCO-style annotation dictionary\n    output_json_dict = {\n        'images': [],\n        'annotations': [],\n        'categories': []\n    }\n    \n    # Iterate through annotated samples\n    for annot_idx in annot_idx_list:\n        # Process annotations and add to the output dictionary\n    \n    # Iterate through non-annotated samples\n    for non_annot_idx in non_annot_idx_list:\n        # Process non-annotations and add to the output dictionary\n    \n    # Save the output dictionary as a JSON file\n    with open(output_json_path, 'w') as f:\n        json.dump(output_json_dict, f)\n\n# Convert annotations to COCO format for training and validation datasets\nconvert_to_coco(train_annots, train_non_annots, 'train_output.json')\nconvert_to_coco(val_annots, val_non_annots, 'val_output.json')\n\n# Load a pre-defined MMDetection configuration file\ncfg = Config.fromfile('mmdetection_config.py')\n\n# Modify the configuration to match the dataset and training settings\ncfg.dataset_type = 'CocoDataset'\ncfg.classes = 'labels.txt'\ncfg.data_root = 'data/'\n\n# ...\n\n# Train the model\ndatasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\ntrain_detector(model, datasets, cfg, distributed=False, validate=True)\n\n# Initialize the trained model for inference\nmodel = init_detector(cfg, 'model_output/epoch_12.pth')\n\n# Perform inference and visualize detection results on sample images\nfor i in range(30):\n    img = data[annots[500 + i]]['file_name']\n    img = mmcv.imread('data/images/' + img)\n    result = inference_detector(model, img)\n    show_result_pyplot(model, img, result)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:55:40.364866Z","iopub.execute_input":"2023-09-18T15:55:40.365269Z","iopub.status.idle":"2023-09-18T15:55:40.379756Z","shell.execute_reply.started":"2023-09-18T15:55:40.365230Z","shell.execute_reply":"2023-09-18T15:55:40.378522Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-dbc7e4a116d8>\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    for non_annot_idx in non_annot_idx_list:\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"],"ename":"IndentationError","evalue":"expected an indented block (<ipython-input-7-dbc7e4a116d8>, line 47)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}